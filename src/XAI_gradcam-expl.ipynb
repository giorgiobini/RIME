{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf4601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath('.'))\n",
    "\n",
    "# use the ImageNet transformation\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# define a 1 image dataset\n",
    "dataset = datasets.ImageFolder(root=os.path.join(ROOT_DIR,'src','Elephant'), transform=transform)\n",
    "\n",
    "# define the dataloader to load that single image\n",
    "dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a909dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        # get the pretrained VGG19 network\n",
    "        self.vgg = vgg19(pretrained=True)\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.vgg.features[:36]\n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.vgg.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb16b51-7c60-407a-94ed-362c717b3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG()\n",
    "\n",
    "# set the evaluation mode\n",
    "vgg.eval()\n",
    "\n",
    "# get the image from the dataloader\n",
    "img, _ = next(iter(dataloader))\n",
    "\n",
    "# get the most likely prediction of the model\n",
    "pred = vgg(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42610adf-e9eb-4bcd-9e70-c2008f88481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (24): ReLU(inplace=True)\n",
       "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (26): ReLU(inplace=True)\n",
       "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (31): ReLU(inplace=True)\n",
       "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (33): ReLU(inplace=True)\n",
       "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (35): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.features_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a94e9a1c-5f32-4081-9a3e-ab72c844c9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29790b27-0754-445c-8839-0809896e50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:, 386].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5987922-5c62-4e34-8588-8cbea9c950c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = vgg.get_activations_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73bc66c8-4498-405f-a376-c1b1e054cd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 14, 14])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3df82dd5-5f57-4272-bec1-d5a4258d7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1911d66a-db1c-4050-abfa-90285bc1916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b64901e7-fcdb-4767-bcb5-a533c962a000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(gradients, dim=[0, 3, 2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fca143d0-1f10-4b1b-9ac8-3a96e77fc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = vgg.get_activations(img).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bec8a47-9f62-450d-9cb0-7f4f327be2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 14, 14])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5e71e09-299e-4ce8-a880-cd48eaec2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efbc1d49-856b-4228-a996-3a09b3980901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 14, 14])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77b9ceb9-117f-4add-9158-7a1f420583a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a50cf3a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "heatmap /= torch.max(heatmap)\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3b557-7d02-47a6-aa81-8193b45054f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a58214-56d4-4c1c-b31f-c68f5e3a7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 386].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg.get_activations(img).detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
