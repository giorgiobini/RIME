{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebb322",
   "metadata": {},
   "outputs": [],
   "source": [
    "its_jupyter_notebook = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8ae948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import dataset.preprocessing as utils\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27767bbf-e1f6-48fa-be38-41711fd68ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrobust\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.2g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mannot_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlinecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcbar_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcbar_ax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msquare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Plot rectangular data as a color-encoded matrix.\n",
       "\n",
       "This is an Axes-level function and will draw the heatmap into the\n",
       "currently-active Axes if none is provided to the ``ax`` argument.  Part of\n",
       "this Axes space will be taken and used to plot a colormap, unless ``cbar``\n",
       "is False or a separate Axes is provided to ``cbar_ax``.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : rectangular dataset\n",
       "    2D dataset that can be coerced into an ndarray. If a Pandas DataFrame\n",
       "    is provided, the index/column information will be used to label the\n",
       "    columns and rows.\n",
       "vmin, vmax : floats, optional\n",
       "    Values to anchor the colormap, otherwise they are inferred from the\n",
       "    data and other keyword arguments.\n",
       "cmap : matplotlib colormap name or object, or list of colors, optional\n",
       "    The mapping from data values to color space. If not provided, the\n",
       "    default will depend on whether ``center`` is set.\n",
       "center : float, optional\n",
       "    The value at which to center the colormap when plotting divergant data.\n",
       "    Using this parameter will change the default ``cmap`` if none is\n",
       "    specified.\n",
       "robust : bool, optional\n",
       "    If True and ``vmin`` or ``vmax`` are absent, the colormap range is\n",
       "    computed with robust quantiles instead of the extreme values.\n",
       "annot : bool or rectangular dataset, optional\n",
       "    If True, write the data value in each cell. If an array-like with the\n",
       "    same shape as ``data``, then use this to annotate the heatmap instead\n",
       "    of the data. Note that DataFrames will match on position, not index.\n",
       "fmt : str, optional\n",
       "    String formatting code to use when adding annotations.\n",
       "annot_kws : dict of key, value mappings, optional\n",
       "    Keyword arguments for :meth:`matplotlib.axes.Axes.text` when ``annot``\n",
       "    is True.\n",
       "linewidths : float, optional\n",
       "    Width of the lines that will divide each cell.\n",
       "linecolor : color, optional\n",
       "    Color of the lines that will divide each cell.\n",
       "cbar : bool, optional\n",
       "    Whether to draw a colorbar.\n",
       "cbar_kws : dict of key, value mappings, optional\n",
       "    Keyword arguments for :meth:`matplotlib.figure.Figure.colorbar`.\n",
       "cbar_ax : matplotlib Axes, optional\n",
       "    Axes in which to draw the colorbar, otherwise take space from the\n",
       "    main Axes.\n",
       "square : bool, optional\n",
       "    If True, set the Axes aspect to \"equal\" so each cell will be\n",
       "    square-shaped.\n",
       "xticklabels, yticklabels : \"auto\", bool, list-like, or int, optional\n",
       "    If True, plot the column names of the dataframe. If False, don't plot\n",
       "    the column names. If list-like, plot these alternate labels as the\n",
       "    xticklabels. If an integer, use the column names but plot only every\n",
       "    n label. If \"auto\", try to densely plot non-overlapping labels.\n",
       "mask : bool array or DataFrame, optional\n",
       "    If passed, data will not be shown in cells where ``mask`` is True.\n",
       "    Cells with missing values are automatically masked.\n",
       "ax : matplotlib Axes, optional\n",
       "    Axes in which to draw the plot, otherwise use the currently-active\n",
       "    Axes.\n",
       "kwargs : other keyword arguments\n",
       "    All other keyword arguments are passed to\n",
       "    :meth:`matplotlib.axes.Axes.pcolormesh`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "ax : matplotlib Axes\n",
       "    Axes object with the heatmap.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "clustermap : Plot a matrix using hierachical clustering to arrange the\n",
       "             rows and columns.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       "Plot a heatmap for a numpy array:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> import numpy as np; np.random.seed(0)\n",
       "    >>> import seaborn as sns; sns.set_theme()\n",
       "    >>> uniform_data = np.random.rand(10, 12)\n",
       "    >>> ax = sns.heatmap(uniform_data)\n",
       "\n",
       "Change the limits of the colormap:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.heatmap(uniform_data, vmin=0, vmax=1)\n",
       "\n",
       "Plot a heatmap for data centered on 0 with a diverging colormap:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> normal_data = np.random.randn(10, 12)\n",
       "    >>> ax = sns.heatmap(normal_data, center=0)\n",
       "\n",
       "Plot a dataframe with meaningful row and column labels:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> flights = sns.load_dataset(\"flights\")\n",
       "    >>> flights = flights.pivot(\"month\", \"year\", \"passengers\")\n",
       "    >>> ax = sns.heatmap(flights)\n",
       "\n",
       "Annotate each cell with the numeric value using integer formatting:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.heatmap(flights, annot=True, fmt=\"d\")\n",
       "\n",
       "Add lines between each cell:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.heatmap(flights, linewidths=.5)\n",
       "\n",
       "Use a different colormap:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.heatmap(flights, cmap=\"YlGnBu\")\n",
       "\n",
       "Center the colormap at a specific value:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.heatmap(flights, center=flights.loc[\"Jan\", 1955])\n",
       "\n",
       "Plot every other column label and don't plot row labels:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> data = np.random.randn(50, 20)\n",
       "    >>> ax = sns.heatmap(data, xticklabels=2, yticklabels=False)\n",
       "\n",
       "Don't draw a colorbar:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.heatmap(flights, cbar=False)\n",
       "\n",
       "Use different axes for the colorbar:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> grid_kws = {\"height_ratios\": (.9, .05), \"hspace\": .3}\n",
       "    >>> f, (ax, cbar_ax) = plt.subplots(2, gridspec_kw=grid_kws)\n",
       "    >>> ax = sns.heatmap(flights, ax=ax,\n",
       "    ...                  cbar_ax=cbar_ax,\n",
       "    ...                  cbar_kws={\"orientation\": \"horizontal\"})\n",
       "\n",
       "Use a mask to plot only part of a matrix\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> corr = np.corrcoef(np.random.randn(10, 200))\n",
       "    >>> mask = np.zeros_like(corr)\n",
       "    >>> mask[np.triu_indices_from(mask)] = True\n",
       "    >>> with sns.axes_style(\"white\"):\n",
       "    ...     f, ax = plt.subplots(figsize=(7, 5))\n",
       "    ...     ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True)\n",
       "\u001b[0;31mFile:\u001b[0m      /data01/giorgio/ENTER/envs/dnabert/lib/python3.9/site-packages/seaborn/matrix.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "?sns.heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f4aebf-4c4c-461b-80e2-7d5d88bac9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/giorgio/ENTER/envs/dnabert/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (1,2,16,17,18,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['gene1', 'gene2', 'x1', 'y1', 'w', 'h']\n",
    "df_paris = pd.read_csv(os.path.join(processed_files_dir, 'paris.csv')).filter(columns_to_keep, axis = 1)\n",
    "df_paris['dataset'] = 'paris'\n",
    "df_ricseq = pd.read_csv(os.path.join(processed_files_dir, 'ricseq.csv')).filter(columns_to_keep, axis = 1)\n",
    "df_ricseq['dataset'] = 'ricseq'\n",
    "df_mario = pd.read_csv(os.path.join(processed_files_dir, 'mario.csv')).filter(columns_to_keep, axis = 1)\n",
    "df_mario['dataset'] = 'mario'\n",
    "\n",
    "df_genes_paris_ricseq=pd.read_csv(os.path.join(processed_files_dir, 'df_genes.csv'))[['gene_id', 'cdna', 'length', 'UTR5', 'CDS', 'UTR3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c579d4-2039-4042-b61e-695026b271c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_coord(df_coord, drop_duplicates = True):\n",
    "    #dataset with all the interactinons of the datasets\n",
    "    df_coord['x2'] = df_coord['x1'] + df_coord['w'] \n",
    "    df_coord['y2'] = df_coord['y1'] + df_coord['h'] \n",
    "\n",
    "    df_coord1 = df_coord[['gene1', 'x1', 'x2', 'dataset']].rename({'gene1':'gene_id', 'x1':'start', 'x2':'end'}, axis=1)\n",
    "    df_coord2 = df_coord[['gene2', 'y1', 'y2', 'dataset']].rename({'gene2':'gene_id', 'y1':'start', 'y2':'end'}, axis=1)\n",
    "    if drop_duplicates:\n",
    "        df_coord = pd.concat([df_coord1, df_coord2], axis = 0).drop_duplicates().reset_index(drop = True)\n",
    "    else:\n",
    "        df_coord = pd.concat([df_coord1, df_coord2], axis = 0).reset_index(drop = True)\n",
    "    return df_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2f562f-01b7-45e9-9b36-1036f3a34c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coord = create_df_coord(\n",
    "    pd.concat([df_paris, df_ricseq, df_mario], axis = 0).reset_index(drop = True)\n",
    ").merge(df_genes_paris_ricseq[['gene_id', 'length', 'UTR5', 'CDS', 'UTR3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cb773-9285-4088-abfc-3598b384251f",
   "metadata": {},
   "source": [
    "Splash è un discorso a parte perche ha altre annotazioni dei geni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d74334-f04c-424c-b2b8-b386fed3ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splash = pd.read_csv(os.path.join(processed_files_dir, 'splash.csv')).filter(columns_to_keep, axis = 1)\n",
    "df_splash['dataset'] = 'splash'\n",
    "df_genes_splash=pd.read_csv(os.path.join(processed_files_dir, 'df_genes_splash.csv'))[['gene_id', 'cdna', 'length', 'UTR5', 'CDS', 'UTR3']]\n",
    "\n",
    "df_coord_splash = create_df_coord(\n",
    "    df_splash\n",
    ").merge(df_genes_splash[['gene_id', 'length', 'UTR5', 'CDS', 'UTR3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf48e80-10e9-4282-8f70-0bb42c4125ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (df_coord['end'] <= df_coord['length']).all()\n",
    "assert (df_coord_splash['end'] <= df_coord_splash['length']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da86079-f198-4586-973e-8d4dce9d4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative_sample(len_fake_neg_region, range_to_search_negative, df_coord, num_tries = 100):\n",
    "    s, e = range_to_search_negative\n",
    "    for i in range(num_tries):\n",
    "        try:\n",
    "            start_coord = np.random.randint(s, (e - len_fake_neg_region))\n",
    "            end_coord = start_coord + len_fake_neg_region\n",
    "            for _, row_coord in df_coord.iterrows():\n",
    "                #print( set(range(start_coord,end_coord)) )\n",
    "                assert set(range(start_coord,end_coord)).intersection(set(range(int(row_coord.start),int(row_coord.end)))) == set()\n",
    "            return start_coord, end_coord\n",
    "        except:\n",
    "            if num_tries%10 == 0 :\n",
    "                len_fake_neg_region = len_fake_neg_region//2\n",
    "            continue\n",
    "    else:\n",
    "        return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc229c49-a834-41f7-86fd-4d1a09241410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_fake_neg_region = int(np.round((df_coord.end - df_coord.start).mean(), 0))\n",
    "# print('length of fake negative region =', len_fake_neg_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8454d70-3f77-4eff-a031-8f97779a0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_cdna_slice(x):\n",
    "    try:\n",
    "        assert (x.end-x.start) == len(x['cdna'][x.start:x.end])\n",
    "    except:\n",
    "        print(x.end-x.start)\n",
    "        print( len(x['cdna'][x.start:x.end]) )\n",
    "        print(x.end, x.start, x.gene_id, x.length, len(x.cdna))\n",
    "        assert False\n",
    "    return x['cdna'][x.start:x.end]\n",
    "\n",
    "def check_intersection(a, b, c, d):\n",
    "    a = int(a)\n",
    "    b = int(b)\n",
    "    c = int(c)\n",
    "    d = int(d)\n",
    "    if (len(set(range(a, b)).intersection(set(range(c, d)))) > 0 ):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def create_posneg(df_coord, df_genes, fixed_neg_region = 0):\n",
    "    diz = {}\n",
    "    gene_list = list(set(df_coord.gene_id))\n",
    "    index = 0\n",
    "    to_drop = 0\n",
    "    \n",
    "    #per ogni gene campiono 1 positivo e 1 negativo\n",
    "    for gene in tqdm(gene_list):\n",
    "        df_coord_gene = df_coord[df_coord['gene_id'] == gene]\n",
    "        positive_sampled = df_coord_gene.sample(1).iloc[0]\n",
    "        length = positive_sampled.length\n",
    "        gene_id = positive_sampled.gene_id\n",
    "        dataset = positive_sampled.dataset\n",
    "        positive_start = int(positive_sampled.start)\n",
    "        positive_end = int(positive_sampled.end)\n",
    "        \n",
    "        pc = not np.isnan(positive_sampled.CDS)\n",
    "        if pc == False:\n",
    "            range_to_search_negative = (0, length)\n",
    "            where = 'none'\n",
    "        else:\n",
    "            if check_intersection(positive_start, positive_end, 0, positive_sampled.UTR5):\n",
    "                range_to_search_negative = (0, positive_sampled.UTR5)\n",
    "                where = 'utr5'\n",
    "            elif check_intersection(positive_start, positive_end, positive_sampled.UTR5, positive_sampled.CDS):\n",
    "                range_to_search_negative = (positive_sampled.UTR5, positive_sampled.CDS)\n",
    "                where = 'cds'\n",
    "            elif check_intersection(positive_start, positive_end, positive_sampled.CDS, positive_sampled.UTR3):\n",
    "                range_to_search_negative = (positive_sampled.CDS, positive_sampled.UTR3)\n",
    "                where = 'utr3'\n",
    "        \n",
    "        if range_to_search_negative[-1] > length:\n",
    "            print(range_to_search_negative, gene_id, length)\n",
    "            assert False\n",
    "            \n",
    "        if fixed_neg_region == 0:\n",
    "            len_neg = (positive_end-positive_start)\n",
    "        else:\n",
    "            len_neg = fixed_neg_region\n",
    "        \n",
    "        negative_start, negative_end = create_negative_sample(len_neg, range_to_search_negative, df_coord_gene)\n",
    "        if np.isnan(negative_start):\n",
    "            positive_start, positive_end = np.nan, np.nan #I will drop this positive\n",
    "            to_drop += 1\n",
    "        \n",
    "        actual_neg_len = (negative_end - negative_start)\n",
    "        distance = len_neg-actual_neg_len\n",
    "        \n",
    "        if actual_neg_len < len_neg:\n",
    "            neg_window_is_reduced = True\n",
    "        else:\n",
    "            neg_window_is_reduced = False\n",
    "            \n",
    "        diz[index] = {'gene_id':gene_id, 'start':positive_start, 'end':positive_end, 'length':length, 'dataset':dataset, 'how': 'positive', 'where':where, 'neg_window_is_reduced':neg_window_is_reduced, 'distance':distance}\n",
    "        index += 1\n",
    "        diz[index] = {'gene_id':gene_id, 'start':negative_start, 'end':negative_end, 'length':length, 'dataset':dataset, 'how': 'negative', 'where':where, 'neg_window_is_reduced':neg_window_is_reduced, 'distance':distance}\n",
    "        index += 1\n",
    "        \n",
    "    df_posneg = pd.DataFrame.from_dict(diz, 'index')\n",
    "    df_posneg = df_posneg.merge(df_genes[['gene_id', 'cdna']])\n",
    "    df_posneg = df_posneg.dropna().reset_index(drop = True)\n",
    "    df_posneg['start'] = df_posneg.start.astype(int)\n",
    "    df_posneg['end'] = df_posneg.end.astype(int)\n",
    "    print('# dropped', to_drop)\n",
    "    df_posneg['cdna_slice'] = df_posneg.apply(obtain_cdna_slice, axis = 1)\n",
    "    df_posneg = df_posneg.drop('cdna', axis = 1)\n",
    "    df_posneg = df_posneg.rename({'cdna_slice':'cdna'}, axis = 1)\n",
    "    df_posneg['id_query'] = df_posneg['gene_id'] + '_' + df_posneg['start'].astype(str) + '_' + df_posneg['end'].astype(str)\n",
    "    return df_posneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dadab701-0852-43c9-bb55-a04086957651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543\n"
     ]
    }
   ],
   "source": [
    "genes_to_drop_splash1 = set(df_genes_splash[df_genes_splash.CDS > df_genes_splash.UTR3].gene_id)\n",
    "genes_to_drop_splash2 = set(df_genes_splash[df_genes_splash.UTR5 > df_genes_splash.CDS].gene_id)\n",
    "genes_to_drop_splash = genes_to_drop_splash1.union(genes_to_drop_splash2)\n",
    "print(len(genes_to_drop_splash))\n",
    "df_coord_splash = df_coord_splash[~df_coord_splash.gene_id.isin(genes_to_drop_splash)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "833922ed-b932-4f44-bab0-186f5220015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg_splash.csv')\n",
    "if os.path.isfile(filepath):\n",
    "    df_posneg_splash = pd.read_csv(filepath)\n",
    "else:\n",
    "    df_posneg_splash = create_posneg(df_coord_splash, df_genes_splash, fixed_neg_region = 0)\n",
    "    df_posneg_splash.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b760822-5de5-440a-838e-fd9335ac20e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "genes_to_drop_ricseq1 = set(df_genes_paris_ricseq[df_genes_paris_ricseq.CDS > df_genes_paris_ricseq.UTR3].gene_id)\n",
    "genes_to_drop_ricseq2 = set(df_genes_paris_ricseq[df_genes_paris_ricseq.UTR5 > df_genes_paris_ricseq.CDS].gene_id)\n",
    "genes_to_drop_paris_ricseq = genes_to_drop_ricseq1.union(genes_to_drop_ricseq2)\n",
    "print(len(genes_to_drop_paris_ricseq))\n",
    "df_coord = df_coord[~df_coord.gene_id.isin(genes_to_drop_paris_ricseq)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d917f57-501e-4cce-9bc0-409a31ba9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg_paris_ricseq.csv')\n",
    "if os.path.isfile(filepath):\n",
    "    df_posneg_paris_ricseq = pd.read_csv(filepath)\n",
    "else:\n",
    "    df_posneg_paris_ricseq = create_posneg(df_coord, df_genes_paris_ricseq)\n",
    "    df_posneg_paris_ricseq.to_csv(os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg_paris_ricseq.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef2290dc-d333-4ea1-bf24-b32e23dd8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg.csv')\n",
    "if os.path.isfile(filepath):\n",
    "    df_posneg = pd.read_csv(filepath)\n",
    "else:\n",
    "    df_posneg = pd.concat([df_posneg_paris_ricseq, df_posneg_splash], axis = 0).reset_index(drop = True)\n",
    "    df_posneg.to_csv(os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbdad0-0870-49cb-944e-e8ba740e87f5",
   "metadata": {},
   "source": [
    "### Now the repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbee6c1-0b56-4e26-9366-ba5f74e624cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ricseq, paris, mario\n",
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_repeats.csv')\n",
    "if os.path.isfile(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "else:\n",
    "    mm = pd.read_csv(os.path.join(original_files_dir, 'repeats.mm.bed'), sep = '\\t', header = None)\n",
    "    hs = pd.read_csv(os.path.join(original_files_dir, 'repeats.hs.bed'), sep = '\\t', header = None)\n",
    "\n",
    "    df = pd.concat([mm, hs], axis = 0).reset_index(drop = True)\n",
    "\n",
    "    df = df.rename({0:'chrom', 1:'start', 2:'end', 6:'feature'}, axis = 1)\n",
    "\n",
    "    df = df[['chrom', 'start', 'end', 'feature']]\n",
    "    \n",
    "    info = utils.read_dataframe(os.path.join(original_files_dir, 'index_bio_regions.Tx.RI_ALL.txt'), columns_to_drop = ['Unnamed: 0'])\n",
    "    info1 = info[['chrom_1', 'ensembl_gene_id_1']].rename({'chrom_1':'chrom', 'ensembl_gene_id_1':'gene_id'}, axis = 1)\n",
    "    info2 = info[['chrom_2', 'ensembl_gene_id_2']].rename({'chrom_2':'chrom', 'ensembl_gene_id_2':'gene_id'}, axis = 1)\n",
    "    info = pd.concat([info1, info2], axis = 0).drop_duplicates().reset_index(drop = True)\n",
    "    \n",
    "    # remove the genes not in our datasets\n",
    "    genes_to_remove = set(df.chrom) - set(info.chrom)\n",
    "\n",
    "    df = df[~df.chrom.isin(genes_to_remove)].reset_index(drop = True)\n",
    "\n",
    "    df = df.merge(info)\n",
    "\n",
    "    df = df.merge(df_genes_paris_ricseq).reset_index(drop = True)\n",
    "\n",
    "    assert (df.length >= df.end).all()\n",
    "\n",
    "    df['start'] = df.start.astype(int)\n",
    "    df['end'] = df.end.astype(int)\n",
    "    df['cdna_slice'] = df.apply(obtain_cdna_slice, axis = 1)\n",
    "    df = df.drop('cdna', axis = 1)\n",
    "    df = df.rename({'cdna_slice':'cdna'}, axis = 1)\n",
    "    df['id_query'] = df['gene_id'] + '_' + df['start'].astype(str) + '_' + df['end'].astype(str)\n",
    "    \n",
    "    \n",
    "    interacting_list = []\n",
    "    for _, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        interacting = False\n",
    "        gene = row.gene_id\n",
    "        region = set(range(int(row.start), int(row.end)))\n",
    "        int_subset = df_coord[df_coord.gene_id == gene]\n",
    "        for _, row_int in int_subset.iterrows():\n",
    "            region_int = set(range(int(row_int.start), int(row_int.end)))\n",
    "            if len(region.intersection(region_int)) > 0:\n",
    "                interacting = True\n",
    "        interacting_list.append(interacting)\n",
    "        \n",
    "    df['interacting'] = interacting_list\n",
    "    df['len_feature'] = df['end']-df['start']\n",
    "    df.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "76555120-8d05-4a0d-a99f-084dab3b9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_repeats_splash.csv')\n",
    "\n",
    "if os.path.isfile(filepath):\n",
    "    sp_r = pd.read_csv(filepath)\n",
    "else:\n",
    "    #SPLASH\n",
    "    df_splash = pd.read_csv(os.path.join(processed_files_dir, f'splash.csv'))\n",
    "    df_splash['dataset'] = 'splash'\n",
    "    df_coord = create_df_coord(df_splash)\n",
    "\n",
    "\n",
    "    df_genes_splash = pd.read_csv(os.path.join(processed_files_dir, f'df_genes_splash.csv'))\n",
    "    sp_r = pd.read_csv(os.path.join(original_files_dir, 'splash', 'repeats.bed'), sep = '\\t', header = None)\n",
    "    sp_r = sp_r.merge(df_genes_splash[['gene_id', 'gene_name', 'length']], left_on = 0, right_on = 'gene_name').filter(['gene_id', 'gene_name', 1, 2, 4, 6, 10, 'length'], axis = 1)\n",
    "    sp_r = sp_r.rename({1:'start', 2:'end', 4:'len_feature', 6:'feature', 10:'other_feature_name'}, axis = 1)\n",
    "\n",
    "    interacting_list = []\n",
    "    for _, row in tqdm(sp_r.iterrows(), total = sp_r.shape[0]):\n",
    "        interacting = False\n",
    "        gene = row.gene_id\n",
    "        region = set(range(int(row.start), int(row.end)))\n",
    "        int_subset = df_coord[df_coord.gene_id == gene]\n",
    "        for _, row_int in int_subset.iterrows():\n",
    "            region_int = set(range(int(row_int.start), int(row_int.end)))\n",
    "            if len(region.intersection(region_int)) > 0:\n",
    "                interacting = True\n",
    "        interacting_list.append(interacting)\n",
    "\n",
    "    sp_r['interacting'] = interacting_list\n",
    "    sp_r.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a6cff-b047-4546-b59c-bc160cedd004",
   "metadata": {},
   "source": [
    "# Create df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95accfbc-a5bb-4805-9b41-e5f603c78f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f03d3d1-393f-466b-88a4-ecdaced85daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query = pd.concat([df[['id_query', 'cdna']], df_posneg[['id_query', 'cdna']]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc5a4d-3a5a-4f41-85a7-8e3d06dbaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(os.path.join(emb_dir, '32'))\n",
    "all_files = list(pd.Series(all_files).str.extractall('(.*)\\.npy').reset_index()[0])\n",
    "df_query = df_query[~df_query.id_query.isin(all_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "579f8ee2-1a0e-495f-8bfe-dd8231e29084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query.to_csv(os.path.join(emb_dir, 'embedding_query.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3e6d9c5-e80d-4d09-b317-19da4ecbf7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated # hours: 21.15\n",
      "estimated # days: 0.88\n",
      "estimated terabytes (pessimistic): 0.92\n",
      "estimated terabytes (realistic): 0.6\n"
     ]
    }
   ],
   "source": [
    "def estimate_time_and_space(n_samples):\n",
    "    #TIME\n",
    "    minutes = 3219*n_samples/(228278)\n",
    "    hours = minutes/60\n",
    "    days = hours/24\n",
    "    print('estimated # hours:', np.round(hours, 2))\n",
    "    print('estimated # days:', np.round(days, 2))\n",
    "\n",
    "    mb = 10.2*n_samples\n",
    "    gb = mb/1000\n",
    "    tb = gb/1000\n",
    "    print('estimated terabytes (pessimistic):', np.round(tb, 2))\n",
    "    mb = 1995*n_samples/(300)\n",
    "    gb = mb/1000\n",
    "    tb = gb/1000\n",
    "    print('estimated terabytes (realistic):', np.round(tb, 2))\n",
    "estimate_time_and_space(df_query.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff9ffc-c971-476d-a326-29ee4422577e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1fc2de1-18aa-4969-bca7-cd71210a6c8e",
   "metadata": {},
   "source": [
    "# Check  (to drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc482e0-00af-4544-804e-bab780556ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = pd.read_csv(os.path.join(original_files_dir, 'repeats.mm.bed'), sep = '\\t', header = None)\n",
    "hs = pd.read_csv(os.path.join(original_files_dir, 'repeats.hs.bed'), sep = '\\t', header = None)\n",
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_repeats.csv')\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa2aac05-591c-4e71-b243-35f8beafb25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SINE              22452\n",
       "Simple_repeat     21574\n",
       "LINE              12217\n",
       "LTR                8321\n",
       "DNA                6619\n",
       "Low_complexity     3927\n",
       "snRNA               549\n",
       "srpRNA              290\n",
       "Satellite           178\n",
       "rRNA                176\n",
       "Retroposon          133\n",
       "Unknown              73\n",
       "scRNA                54\n",
       "tRNA                 49\n",
       "RC                   35\n",
       "Name: 6, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs[6].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca26f8b-e897-40d4-9310-dafb1941e5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Simple_repeat     40298\n",
       "SINE              33493\n",
       "LINE              14733\n",
       "LTR               13606\n",
       "DNA                7503\n",
       "Low_complexity     6706\n",
       "Unknown            1616\n",
       "Satellite           673\n",
       "Retroposon          205\n",
       "scRNA               132\n",
       "snRNA               111\n",
       "tRNA                 73\n",
       "rRNA                 45\n",
       "srpRNA               39\n",
       "RC                   35\n",
       "Name: feature, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.feature.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8090568-7cb8-4748-9bc2-5e2cc50c07a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " 'Not present',\n",
       " 'SINE',\n",
       " 'Simple_repeat',\n",
       " 'LINE',\n",
       " 'LTR',\n",
       " 'DNA',\n",
       " 'Low_complexity',\n",
       " 'SINE, SINE',\n",
       " 'Simple_repeat, Simple_repeat',\n",
       " 'SINE, LINE',\n",
       " 'LINE, SINE',\n",
       " 'LINE, LINE',\n",
       " 'Simple_repeat, SINE',\n",
       " 'LTR, LTR',\n",
       " 'LTR, SINE',\n",
       " 'DNA, SINE',\n",
       " 'SINE, LTR',\n",
       " 'SINE, Simple_repeat',\n",
       " 'SINE, DNA',\n",
       " 'LTR, LINE',\n",
       " 'DNA, DNA',\n",
       " 'Simple_repeat, Simple_repeat, Simple_repeat',\n",
       " 'SINE, Simple_repeat, SINE',\n",
       " 'Low_complexity, Simple_repeat',\n",
       " 'Simple_repeat, Low_complexity',\n",
       " 'DNA, LINE',\n",
       " 'SINE, LINE, SINE',\n",
       " 'LINE, Simple_repeat',\n",
       " 'LINE, LTR',\n",
       " 'LINE, DNA',\n",
       " 'Simple_repeat, LINE',\n",
       " 'SINE, SINE, SINE',\n",
       " 'LINE, Simple_repeat, LINE',\n",
       " 'DNA, Simple_repeat',\n",
       " 'SINE, DNA, SINE',\n",
       " 'Simple_repeat, DNA',\n",
       " 'LTR, DNA',\n",
       " 'DNA, LTR',\n",
       " 'Low_complexity, Low_complexity',\n",
       " 'Satellite',\n",
       " 'Retroposon',\n",
       " 'Simple_repeat, Simple_repeat, Simple_repeat, Simple_repeat',\n",
       " 'Unknown',\n",
       " 'LINE, Simple_repeat, SINE',\n",
       " 'LTR, LTR, SINE',\n",
       " 'SINE, Low_complexity',\n",
       " 'Low_complexity, SINE',\n",
       " 'LINE, LINE, LINE',\n",
       " 'Simple_repeat, LTR',\n",
       " 'SINE, LTR, SINE',\n",
       " 'SINE, DNA, LINE',\n",
       " 'LTR, LTR, LTR',\n",
       " 'Simple_repeat, LTR, Simple_repeat',\n",
       " 'LINE, LINE, SINE',\n",
       " 'SINE, LINE, LINE',\n",
       " 'LINE, SINE, LINE',\n",
       " 'SINE, SINE, LTR',\n",
       " 'SINE, SINE, LINE',\n",
       " 'DNA, SINE, SINE',\n",
       " 'SINE, SINE, DNA',\n",
       " 'SINE, DNA, DNA',\n",
       " 'LTR, Simple_repeat, LTR',\n",
       " 'DNA, Simple_repeat, SINE',\n",
       " 'SINE, LINE, LTR',\n",
       " 'SINE, Retroposon, LINE',\n",
       " 'SINE, Simple_repeat, Simple_repeat, LINE',\n",
       " 'SINE, Simple_repeat, LINE',\n",
       " 'Simple_repeat, SINE, SINE',\n",
       " 'LINE, Low_complexity',\n",
       " 'Simple_repeat, SINE, Simple_repeat',\n",
       " 'LINE, SINE, LTR',\n",
       " 'SINE, Low_complexity, LTR',\n",
       " 'Retroposon, Simple_repeat',\n",
       " 'Low_complexity, DNA',\n",
       " 'LTR, SINE, LTR',\n",
       " 'SINE, Simple_repeat, DNA',\n",
       " 'LTR, Simple_repeat',\n",
       " 'Simple_repeat, Retroposon',\n",
       " 'LINE, Low_complexity, LINE',\n",
       " 'SINE, Simple_repeat, Simple_repeat',\n",
       " 'SINE, SINE, Simple_repeat',\n",
       " 'LINE, DNA, DNA',\n",
       " 'Low_complexity, Simple_repeat, Simple_repeat',\n",
       " 'LINE, LINE, Simple_repeat',\n",
       " 'SINE, LTR, Simple_repeat',\n",
       " 'SINE, Simple_repeat, Retroposon',\n",
       " 'LINE, Simple_repeat, DNA',\n",
       " 'Simple_repeat, Low_complexity, Simple_repeat',\n",
       " 'tRNA',\n",
       " 'LTR, DNA, SINE',\n",
       " 'snRNA, DNA',\n",
       " 'SINE, LINE, Simple_repeat, SINE',\n",
       " 'Simple_repeat, Simple_repeat, LINE',\n",
       " 'LINE, Low_complexity, DNA',\n",
       " 'Low_complexity, LINE',\n",
       " 'Simple_repeat, Simple_repeat, SINE',\n",
       " 'SINE, Low_complexity, SINE',\n",
       " 'Simple_repeat, DNA, Simple_repeat',\n",
       " 'Simple_repeat, SINE, LINE',\n",
       " 'SINE, LTR, LINE',\n",
       " 'DNA, DNA, LTR',\n",
       " 'LINE, LINE, LTR',\n",
       " 'Simple_repeat, Satellite',\n",
       " 'rRNA, DNA',\n",
       " 'SINE, Retroposon',\n",
       " 'SINE, Simple_repeat, LINE, SINE',\n",
       " 'LTR, LINE, SINE',\n",
       " 'LTR, LTR, LINE',\n",
       " 'DNA, Simple_repeat, DNA',\n",
       " 'srpRNA',\n",
       " 'Low_complexity, LTR',\n",
       " 'LINE, LINE, Simple_repeat, SINE',\n",
       " 'Simple_repeat, Low_complexity, Low_complexity, Simple_repeat',\n",
       " 'DNA, RC',\n",
       " 'Simple_repeat, SINE, DNA',\n",
       " 'SINE, LTR, LTR',\n",
       " 'Simple_repeat, LINE, Simple_repeat, SINE',\n",
       " 'rRNA',\n",
       " 'Low_complexity, rRNA',\n",
       " 'LTR, Simple_repeat, SINE',\n",
       " 'SINE, LTR, Low_complexity',\n",
       " 'Simple_repeat, Simple_repeat, Simple_repeat, Simple_repeat, SINE',\n",
       " 'SINE, scRNA',\n",
       " 'Satellite, LINE',\n",
       " 'LINE, LTR, Simple_repeat, LTR',\n",
       " 'SINE, LTR, LINE, LTR',\n",
       " 'DNA, Simple_repeat, LINE',\n",
       " 'SINE, srpRNA',\n",
       " 'DNA, DNA, DNA',\n",
       " 'rRNA, LINE',\n",
       " 'LINE, rRNA, SINE',\n",
       " 'SINE, Satellite',\n",
       " 'Retroposon, SINE',\n",
       " 'LINE, Simple_repeat, LINE, SINE',\n",
       " 'snRNA',\n",
       " 'snRNA, SINE',\n",
       " 'Simple_repeat, Low_complexity, SINE',\n",
       " 'Simple_repeat, Simple_repeat, Low_complexity',\n",
       " 'LTR, DNA, LTR']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.evaluation import obtain_enhn_easypos_smartneg, calc_corr_perf_conf, calc_corr_quality_perf, calc_corr_quality_conf, ModelResultsManager, calculate_correlations, balancing_only_for_one_task, obtain_all_model_auc, remove_outliers, map_thermodynamic_columns, obtain_df_auc, replace_outliers_with_nan_and_make_positive, obtain_sr_nosr, map_dataset_to_hp\n",
    "\n",
    "external_dataset_dir = os.path.join(dataset_files_dir, 'external_dataset', '200_test_tables')\n",
    "\n",
    "model_name = 'arch2_PSORALENtrained_PARISval0074'#'arch2_PARISfinetuned_PARIStest0023_PARISfinetunedFPweight_PARIStest0086' #'arch2_PSORALENtrained_PARISval0074' \n",
    "PARIS_FINETUNED_MODEL = True\n",
    "SPLASH_TRAINED_MODEL = False\n",
    "energy_columns = ['IntaRNA', 'priblast', 'RNAplex', 'rnacofold', 'assa', 'RNAhybrid', 'RNAup', 'risearch2']\n",
    "list_of_HQ_datasets = ['parisHQ', 'paris_mouse_HQ', 'ricseqHQ']\n",
    "list_of_datasets = list_of_HQ_datasets + ['psoralen', 'paris', 'paris_mouse', 'ricseq', 'mario', 'splash']\n",
    "\n",
    "modelRM = ModelResultsManager(model_name = model_name, \n",
    "                            dimension = 200, \n",
    "                            chkpt_directory = os.path.join(ROOT_DIR, 'checkpoints'), \n",
    "                            rna_rna_files_dir = rna_rna_files_dir, \n",
    "                            test_info_directory = metadata_dir, \n",
    "                            other_tools = energy_columns, \n",
    "                            other_tools_dir = external_dataset_dir)\n",
    "\n",
    "res = modelRM.get_experiment_data(\n",
    "        experiment = 'paris', \n",
    "        paris_test = True, \n",
    "        paris_finetuned_model = PARIS_FINETUNED_MODEL, \n",
    "        specie_paris = 'human',\n",
    "        paris_hq = False,\n",
    "        paris_hq_threshold = 1,\n",
    "        n_reads_paris = 1,\n",
    "        interlen_OR_nreads_paris = False,\n",
    "        splash_trained_model = False,\n",
    "        only_test_splash_ricseq_mario = False,\n",
    "        n_reads_ricseq = 1,\n",
    "        logistic_regression_models = {},\n",
    ")\n",
    "\n",
    "list(res.feature1.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d89e0-0758-43f8-9e73-36087206c214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
