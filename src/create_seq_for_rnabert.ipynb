{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fd7e20-8dab-4f31-a886-2801a259b193",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b7acf7-7061-49e6-b0d7-8480984933f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "its_jupyter_notebook = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685f531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "<class 'transformers.tokenization_dna.DNATokenizer'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from util.encoding_sequences import build_kmers\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if its_jupyter_notebook:\n",
    "    sys.argv = [''] #Remove this if it's not a jupyter notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfdaa078-478c-4e41-b3c6-57ae5a98fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.abspath('.'))\n",
    "dnabert_dir = os.path.join(ROOT_DIR, 'dataset', 'pre_trained_DNABERT')\n",
    "processed_files_dir = os.path.join(ROOT_DIR, 'dataset', 'processed_files')\n",
    "rnabert_data_dir = os.path.join(dnabert_dir, 'rna_data')\n",
    "\n",
    "if not os.path.exists(rnabert_data_dir):\n",
    "    os.mkdir(rnabert_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c139ea-42c6-4b3d-980a-109cb0acbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(processed_files_dir,\"df_cdna.csv\"))\n",
    "#mmseq = pd.read_csv(os.path.join(processed_files_dir,\"mmseq2_clusters.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b80120-3e53-4739-b52d-c606c3c78cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.6, frac_val=0.15, frac_test=0.25,\n",
    "                                         random_state=None):\n",
    "    #credits: https://stackoverflow.com/questions/50781562/stratified-splitting-of-pandas-dataframe-into-training-validation-and-test-set\n",
    "    '''\n",
    "    Splits a Pandas dataframe into three subsets (train, val, and test)\n",
    "    following fractional ratios provided by the user, where each subset is\n",
    "    stratified by the values in a specific column (that is, each subset has\n",
    "    the same relative frequency of the values in the column). It performs this\n",
    "    splitting by running train_test_split() twice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_input : Pandas dataframe\n",
    "        Input dataframe to be split.\n",
    "    stratify_colname : str\n",
    "        The name of the column that will be used for stratification. Usually\n",
    "        this column would be for the label.\n",
    "    frac_train : float\n",
    "    frac_val   : float\n",
    "    frac_test  : float\n",
    "        The ratios with which the dataframe will be split into train, val, and\n",
    "        test data. The values should be expressed as float fractions and should\n",
    "        sum to 1.0.\n",
    "    random_state : int, None, or RandomStateInstance\n",
    "        Value to be passed to train_test_split().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train, df_val, df_test :\n",
    "        Dataframes containing the three splits.\n",
    "    '''\n",
    "\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    if stratify_colname not in df_input.columns:\n",
    "        raise ValueError('%s is not a column in the dataframe' % (stratify_colname))\n",
    "\n",
    "    X = df_input # Contains all columns.\n",
    "    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          stratify=y,\n",
    "                                                          test_size=(1.0 - frac_train),\n",
    "                                                          random_state=random_state)\n",
    "\n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n",
    "                                                      y_temp,\n",
    "                                                      stratify=y_temp,\n",
    "                                                      test_size=relative_frac_test,\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "\n",
    "    return df_train, df_val, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543cf2aa-d2a1-4488-a634-f5b9908cb1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_stratified_into_train_val_test(df, stratify_colname='species', frac_train=0.7, frac_val=0.15, frac_test=0.15, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51bb13df-5e27-42a0-b429-d849b9396173",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(df_train.gene_id).intersection(set(df_val.gene_id)) == set()\n",
    "assert set(df_val.gene_id).intersection(set(df_test.gene_id)) == set()\n",
    "assert set(df_train.gene_id).intersection(set(df_test.gene_id)) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f92ff54-b519-4096-81f7-0cfc22658d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNABERT Supplementary materials\n",
    "# The length of each sub-sequence lies in the range of 5 and 510. \n",
    "# Specifically, with a 50% probability, we set the length of a sub-sequence as 510. \n",
    "# With another 50% probability, we set its length as a random integer between 5 and 510.  \n",
    "\n",
    "train_file = os.path.join(rnabert_data_dir, 'train_6mers.txt')\n",
    "val_file = os.path.join(rnabert_data_dir, 'val_6mers.txt')\n",
    "test_file = os.path.join(rnabert_data_dir, 'test_6mers.txt')\n",
    "\n",
    "def xrange(x):\n",
    "    return iter(range(x))\n",
    "\n",
    "def window(a, win_size):\n",
    "    return [a[i:i+win_size] for i in xrange(len(a)-(win_size-1))]\n",
    "\n",
    "def write_sequences(split, path, frequency = 510):\n",
    "    txtfile = open(path, \"w\")\n",
    "    for _, row in tqdm(split.iterrows(), total=split.shape[0]):\n",
    "        sequence = row.cdna\n",
    "        if len(sequence) < 510:\n",
    "            s = build_kmers(sequence, k = 6)\n",
    "            txtfile.write(s + \"\\n\")\n",
    "        else:   \n",
    "            c = 0\n",
    "            for seq in window(sequence, 510):\n",
    "                if c%frequency == 0:\n",
    "                    if np.random.rand()>0.5:\n",
    "                        seq = seq[0:np.random.randint(5, 510)]\n",
    "                    s = build_kmers(seq, k = 6)\n",
    "                    txtfile.write(s + \"\\n\")\n",
    "                c+=1\n",
    "    txtfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe5bb8e-e0d1-48c1-a62d-4121e8188f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5404a71f4da84ecfa7efc92d72de07a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_sequences(df_val, val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3ce32d-6e45-43f5-8a6b-6e7fcd4bf6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5c266226b848e5879f1e21f5449e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_sequences(df_test, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "179772e6-ea7b-4226-94a0-90bd94034184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273b0d0756384078bd5fd0a10962d7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_sequences(df_train, train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee9733-f72c-40df-aa20-f43aead6e9fb",
   "metadata": {},
   "source": [
    "## Create a fake small set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "599f143c-c65f-4055-bf8f-44b0520ae0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file = os.path.join(rnabert_data_dir, 'val_6mers.txt')\n",
    "fake_file = os.path.join(rnabert_data_dir, 'fake_6mers.txt')\n",
    "\n",
    "val = open(val_file, \"r\")\n",
    "fake = open(fake_file, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "600fc036-996e-4a29-bdc4-860b878e7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = val.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e39d0d-d143-430a-8e79-e78874468bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0] == content[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "527c7088-3424-4c90-a7ea-edad6992d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_write = ''\n",
    "for i in range(500):\n",
    "    to_write += content[i]\n",
    "val.close()\n",
    "fake.write(to_write)\n",
    "fake.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
