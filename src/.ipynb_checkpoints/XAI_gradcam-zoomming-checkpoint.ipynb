{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffec1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "its_jupyter_notebook = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf4601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/giorgio/ENTER/envs/rnarna/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /data01/giorgio/ENTER/envs/rnarna/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops10select_int4callERKNS_6TensorEll\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import sys\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.insert(0, '..')\n",
    "from config import *\n",
    "import util.misc as utils\n",
    "from util import box_ops\n",
    "from util.xai import plot_matrix, get_cdna_slices, forward_func, expl_matrix_treshold, cosine_similarity_expl, estimate_bbox\n",
    "from models.nt_classifier import build as build_model\n",
    "from dataset.data import (\n",
    "    RNADatasetNT,\n",
    "    EasyPosAugment,\n",
    "    InteractionSelectionPolicy,\n",
    "    SmartNegAugment,\n",
    "    seed_everything,\n",
    ")\n",
    "\n",
    "from config import *\n",
    "\n",
    "if its_jupyter_notebook:\n",
    "    sys.argv = [''] #Remove this if it's not a jupyter notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bfa496-ceec-42c5-877e-30e1219eb7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(ROOT_DIR, 'checkpoints', 'df_nt_changed_fakeinteractionregions_and_couples_id_column') #'binary_cl2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82cdfba-eed8-4207-8a60-9dc59047db0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243882/346107875.py:2: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_nt = pd.read_csv(os.path.join(metadata_dir, f'df_nt.csv'))\n"
     ]
    }
   ],
   "source": [
    "df_genes_nt = pd.read_csv(os.path.join(metadata_dir, f'df_genes_nt.csv'))\n",
    "df_nt = pd.read_csv(os.path.join(metadata_dir, f'df_nt.csv'))\n",
    "res = pd.read_csv(os.path.join(checkpoint_dir, 'test_results.csv'))\n",
    "res['confidence'] = abs(res['probability'] - 0.5) + 0.5\n",
    "\n",
    "#not in training pairs\n",
    "file_train = os.path.join(rna_rna_files_dir, \"gene_pairs_training_nt.txt\")\n",
    "with open(file_train, \"rb\") as fp:   # Unpickling\n",
    "    gene_pairs_train = pickle.load(fp)\n",
    "\n",
    "df_nt = pd.read_csv(os.path.join(metadata_dir, f'df_nt.csv'))\n",
    "regex = df_nt[df_nt.couples.isin(gene_pairs_train)].couples_id.str.extractall('(.*)_(.*)').reset_index()\n",
    "df_train = regex\n",
    "df_train['g1'] = regex[0]\n",
    "df_train['g2'] = regex[1]\n",
    "df_train_genes = set(df_train['g1']).union(set(df_train['g2']))\n",
    "\n",
    "not_in_train = res[~(res.gene1_original.isin(df_train_genes) | res.gene2_original.isin(df_train_genes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20dd3f75-efec-4cc3-a30f-0eea56bd0589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc overall: 0.68\n",
      "acc on positive task: 0.34\n",
      "I will try gradcam over 11 sequences\n"
     ]
    }
   ],
   "source": [
    "CONFIDENCE_LEVEL = 0.6\n",
    "\n",
    "query = not_in_train[(not_in_train.confidence>CONFIDENCE_LEVEL)]\n",
    "print(f'acc overall: {np.round((query.ground_truth == query.prediction).sum()/query.shape[0], 2)}')\n",
    "query = query[(query.ground_truth == 1)]\n",
    "print(f'acc on positive task: {np.round((query.ground_truth == query.prediction).sum()/query.shape[0], 2)}')\n",
    "query = query[(query.prediction == 1)]\n",
    "print(f'I will try gradcam over {query.shape[0]} sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cf954d7-18f7-4319-bddd-9e4af43b3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df_nt_query\n",
    "\n",
    "# df_nt_query = df_nt[df_nt.couples.isin(list(query.id_sample))]\n",
    "\n",
    "query_id = query.g1+query.g2\n",
    "df_nt_id = df_nt.gene1+df_nt.gene2\n",
    "df_nt_query = df_nt[df_nt_id.isin(list(query_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ba230-6a4b-4b80-9348-4d11be12b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243882/3834547494.py:14: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_nt = pd.read_csv(os.path.join(metadata_dir, f'df_nt.csv'))\n"
     ]
    }
   ],
   "source": [
    "MAX_N_GROUP_SIZE = 300\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "args_path = os.path.join(checkpoint_dir, 'args.pkl')\n",
    "\n",
    "# Load the args namespace from the file\n",
    "with open(args_path, 'rb') as f:\n",
    "    args_dict = pickle.load(f)\n",
    "\n",
    "# Convert the dictionary to an argparse.Namespace object\n",
    "args = argparse.Namespace(**args_dict)\n",
    "args.resume = os.path.join(checkpoint_dir, 'epoch31.pth') # best_model\n",
    "\n",
    "df_nt = pd.read_csv(os.path.join(metadata_dir, f'df_nt.csv'))\n",
    "df_genes_nt = pd.read_csv(os.path.join(metadata_dir, f'df_genes_nt.csv'))\n",
    "\n",
    "pos_multipliers = {10_000_000:1.,}\n",
    "neg_multipliers = pos_multipliers\n",
    "\n",
    "policies_test = [\n",
    "    EasyPosAugment(\n",
    "        per_sample=1,\n",
    "        interaction_selection=InteractionSelectionPolicy.LARGEST,\n",
    "        width_multipliers=pos_multipliers,\n",
    "        height_multipliers=pos_multipliers,\n",
    "    ),  \n",
    "    SmartNegAugment(\n",
    "        per_sample=1,\n",
    "        interaction_selection=InteractionSelectionPolicy.LARGEST,\n",
    "        width_multipliers=neg_multipliers,\n",
    "        height_multipliers=neg_multipliers,\n",
    "    ),\n",
    "]\n",
    "\n",
    "dataset_test = RNADatasetNT(\n",
    "    gene2info=df_genes_nt,\n",
    "    interactions=df_nt_query,\n",
    "    subset_file='',\n",
    "    augment_policies=policies_test,\n",
    "    data_dir = os.path.join(embedding_dir, '32'),\n",
    "    scaling_factor = 5,\n",
    "    min_n_groups = np.nan,\n",
    "    max_n_groups = MAX_N_GROUP_SIZE,\n",
    ")\n",
    "\n",
    "sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "data_loader_test = DataLoader(dataset_test, 1,\n",
    "                              sampler=sampler_test, drop_last=False,\n",
    "                              collate_fn = utils.collate_fn_nt2,\n",
    "                              num_workers=1)\n",
    "\n",
    "device = torch.device(DEVICE)\n",
    "model = build_model(args)\n",
    "model.to(device)\n",
    "\n",
    "checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae684e-da6e-4793-a680-570e3d3c2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam(model, rna1, rna2, counterfactual = False, cnn_layer = 1):\n",
    "    if cnn_layer == 1:\n",
    "        gradients = model.get_activations_gradient1()\n",
    "        activations = model.get_activations1(rna1, rna2).detach()\n",
    "        \n",
    "    elif cnn_layer == 2:\n",
    "        gradients = model.get_activations_gradient2()\n",
    "        activations = model.get_activations2(rna1, rna2).detach()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    n_channels = activations.shape[1]\n",
    "    if counterfactual:\n",
    "        for i in range(n_channels):\n",
    "            activations[:, i, :, :] *= - pooled_gradients[i]\n",
    "    else:\n",
    "        for i in range(n_channels):\n",
    "            activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    #heatmap /= torch.max(heatmap)\n",
    "    heatmap = np.array(heatmap.cpu().squeeze())\n",
    "    return heatmap\n",
    "\n",
    "def interpolate_expl_matrix(expl_matrix, height, width, normalize = True):\n",
    "    im = Image.fromarray(expl_matrix)\n",
    "    im = im.resize((height, width))\n",
    "    #im = im.resize((width, height))\n",
    "    expl_matrix_reshaped = np.array(im)\n",
    "    if normalize: \n",
    "        expl_matrix_reshaped = (expl_matrix_reshaped - expl_matrix_reshaped.min())/(expl_matrix_reshaped.max() - expl_matrix_reshaped.min())\n",
    "    return expl_matrix_reshaped\n",
    "\n",
    "def collect_metrics_and_prediction(matrix, x1, x2, y1, y2, desired_dim = 300):\n",
    "    cos_sim = float(np.round(cosine_similarity_expl(matrix, [x1, x2, y1, y2]), 3))\n",
    "    x1hat, y1hat, what, hhat = estimate_bbox(matrix, desired_dim = desired_dim)\n",
    "    iou_value = float(np.round(box_ops.iou_metric([x1hat, y1hat, what, hhat], \n",
    "                                                  [x1, y1, w, h]), \n",
    "                               2))\n",
    "    return cos_sim, iou_value, x1hat, y1hat, what, hhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ea121-11a6-4e0a-b752-fa2a7701f4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gradcam_results = []\n",
    "treshold = 75\n",
    "\n",
    "for (rna1, rna2), target in tqdm(data_loader_test):\n",
    "    \n",
    "    #rna1 = rna1[:, :, 150:] #drop it\n",
    "    \n",
    "    s = target[0]\n",
    "    interacting = bool(s['interacting'])\n",
    "    \n",
    "    s_bbox = s['bbox']\n",
    "    int_bbox = s['interaction_bbox']\n",
    "\n",
    "    row_original = df_nt[(df_nt['gene1'] == s['gene1'])&(df_nt['gene2'] == s['gene2'])]\n",
    "    row_swapped = df_nt[(df_nt['gene2'] == s['gene1'])&(df_nt['gene1'] == s['gene2'])]\n",
    "\n",
    "    if len(row_original)>0:\n",
    "        assert len(row_original) == 1\n",
    "        row = row_original.iloc[0]\n",
    "        \n",
    "    elif len(row_swapped)>0:\n",
    "        assert len(row_swapped) == 1\n",
    "        row = row_swapped.iloc[0]\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    x1 = int(int_bbox.x1-s_bbox.x1)\n",
    "    x2 = int(int_bbox.x2-s_bbox.x1)\n",
    "    y1 = int(int_bbox.y1-s_bbox.y1)\n",
    "    y2 = int(int_bbox.y2-s_bbox.y1)\n",
    "    w = x2-x1\n",
    "    h = y2-y1\n",
    "    width = s_bbox.x2-s_bbox.x1\n",
    "    height = s_bbox.y2-s_bbox.y1\n",
    "\n",
    "    outputs = model(rna1.to(device), rna2.to(device))\n",
    "    print(outputs.softmax(-1)[:, 1])\n",
    "    outputs[:, 1].backward()\n",
    "    \n",
    "    expl_matrix = gradcam(model, rna1, rna2, counterfactual = False, cnn_layer = 2)\n",
    "\n",
    "    expl_matrix_reshaped = interpolate_expl_matrix(expl_matrix, height, width)\n",
    "    \n",
    "    desired_dim = int(min(width, height) / 5)\n",
    "    scaling_factor = 150\n",
    "\n",
    "    cos_sim, iou_value, x1hat, y1hat, what, hhat = collect_metrics_and_prediction(expl_matrix_reshaped, x1, x2, y1, y2, desired_dim = desired_dim)\n",
    "    \n",
    "    \n",
    "    expl_matrix_tr = expl_matrix_treshold(expl_matrix_reshaped, treshold = treshold, normalize = True)\n",
    "    cos_sim_tr, iou_value_tr, x1hat_tr, y1hat_tr, what_tr, hhat_tr = collect_metrics_and_prediction(expl_matrix_tr, x1, x2, y1, y2)\n",
    "\n",
    "    \n",
    "    random_expl_matrix = np.random.rand(expl_matrix_reshaped.shape[0], expl_matrix_reshaped.shape[1])\n",
    "    cos_sim_rand, iou_value_rand, x1hat_rand, y1hat_rand, what_rand, hhat_rand = collect_metrics_and_prediction(random_expl_matrix, x1, x2, y1, y2)\n",
    "    \n",
    "    gradcam_results.append(\n",
    "         {\"if\": row.couples, \n",
    "          \"probability\": np.round(float(outputs.softmax(-1)[:, 1]), 3), \n",
    "          \"iou_value\":iou_value, \n",
    "          \"cos_sim\":cos_sim, \n",
    "          \"iou_value_tr\":iou_value_tr, \n",
    "          \"cos_sim_tr\":cos_sim_tr, \n",
    "          \"iou_value_rand\":iou_value_rand, \n",
    "          \"cos_sim_rand\":cos_sim_rand, \n",
    "         }\n",
    "     )\n",
    "    \n",
    "    plot_matrix(expl_matrix_reshaped, \n",
    "                ''.join(['C'for i in range(width)]), \n",
    "                ''.join(['C'for i in range(height)]), \n",
    "                [[x1, y1, w, h]], #crop_bbox =[x1hat, y1hat, what, hhat], \n",
    "                cmap ='viridis', \n",
    "                scaling_factor = scaling_factor,\n",
    "    )\n",
    "    plt.show()\n",
    "        \n",
    "gradcam_results = pd.DataFrame(gradcam_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aaa8e8-7b7b-4621-9ab0-f16a1808fcf6",
   "metadata": {},
   "source": [
    "### Read results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0052f-46b7-4b79-9281-36de3290d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_columns = ['iou_value', 'iou_value_tr', 'iou_value_rand']\n",
    "for c in iou_columns:\n",
    "    print(f'{c}: {str(np.round(gradcam_results[c].mean(), 4))}')\n",
    "\n",
    "for c in iou_columns:\n",
    "    sns.kdeplot(gradcam_results[c], label = c)\n",
    "plt.title(f'IOU values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be7c46-1ebb-4090-88ce-7b31a180ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_columns = ['cos_sim', 'cos_sim_tr', 'cos_sim_rand']\n",
    "for c in cosine_sim_columns:\n",
    "    print(f'{c}: {str(np.round(gradcam_results[c].mean(), 2))}')\n",
    "\n",
    "for c in cosine_sim_columns:\n",
    "    sns.kdeplot(gradcam_results[c], label = c)\n",
    "plt.title(f'Cosine Similarity values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
