{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fd7e20-8dab-4f31-a886-2801a259b193",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685f531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.insert(0, '..')\n",
    "import dataset.preprocessing as utils\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ff3bd-6803-470d-a1bd-3a21e6d1e19b",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497655dd-0964-429a-9985-d99f3cebec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hub = utils.read_dataframe(os.path.join(original_files_dir, 'hub.table.paris.txt'), columns_to_drop = ['Unnamed: 0','gene_name']).rename({'cell_line': 'cell_line_set',\n",
    "                                                                                                                                                    'degree':'n_interactors',\n",
    "                                                                                                                                                    'gene_type': 'gene_type_set',\n",
    "                                                                                                                                                    'species': 'species_set'}, axis = 1)\n",
    "tx = utils.read_dataframe(os.path.join(original_files_dir,'tx_regions.ens99.txt'), columns_to_drop = ['Unnamed: 0','ensembl_transcript_id']).rename({'ensembl_gene_id': 'gene_id'}, axis = 1)\n",
    "cc = utils.read_dataframe(os.path.join(original_files_dir,'controls_controlled.hub.txt'), columns_to_drop = ['Unnamed: 0'])\n",
    "int_or = utils.read_dataframe(os.path.join(original_files_dir, 'rise_paris_tr.new.mapped_interactions.tx_regions.txt'), columns_to_drop = ['Unnamed: 0',  'Unnamed: 0.1', 'gene_name1', 'gene_name2', 'score', 'tx_id_1', 'tx_id_2', 'rise_id', 'type_interaction', 'tx_id_1_localization', 'tx_id_2_localization'])\n",
    "int_or = int_or.drop_duplicates().reset_index(drop = True)\n",
    "df_genes = df_hub.merge(tx, on = 'gene_id')\n",
    "assert df_genes.shape[0] == df_hub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30fa167f-b15a-4b2f-83ed-91248a5ce12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs_full = utils.obtain_df_pos_controls(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f73dcaa-bfa7-4767-9f51-fd299f71c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 80493 pairs interacting (they can have multiple interactions) \n",
      "\n",
      "We have 160145 pairs not interacting \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(set(df_pairs_full.positive))} pairs interacting (they can have multiple interactions) \\n')\n",
    "print(f'We have {len(set(df_pairs_full.negative))} pairs not interacting \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023dbe0c-9ade-49d3-b1ca-6b8573b18187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs_full.to_csv(os.path.join(processed_files_dir, 'df_pairs_full.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d986478-382b-4a55-9f5d-e2207b0beadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(df_pairs_full.positive).intersection(set(int_or.gene_id1 + '_' + int_or.gene_id2))) > 0\n",
    "assert len(set(df_pairs_full.positive).intersection(set(int_or.gene_id2 + '_' + int_or.gene_id1))) > 0\n",
    "\n",
    "assert len(set(df_pairs_full.negative).intersection(set(int_or.gene_id1 + '_' + int_or.gene_id2))) == 0\n",
    "assert len(set(df_pairs_full.negative).intersection(set(int_or.gene_id2 + '_' + int_or.gene_id1))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "525854c0-e941-46c0-9bd0-98d098a4cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = df_pairs_full[['negative']].drop_duplicates().reset_index(drop = True)\n",
    "df_neg[['gene1', 'gene2']] = df_neg['negative'].str.split('_', expand = True)\n",
    "df_neg = df_neg.rename({'negative':'couples'}, axis = 1)\n",
    "\n",
    "df_pairs = df_pairs_full.groupby('positive').agg({'negative': list}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653bf7a5-ed9a-4938-acf7-e7fe258f64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_or[['couples', 'need_to_swap']] = int_or[['gene_id1', 'gene_id2']].apply(utils.create_pairs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85328018-11fc-463e-862c-47b9ec71e253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972 interactions were duplicated (the genes were swopped, now they have a unique couples_id so I can see only now that they are duplicated)\n"
     ]
    }
   ],
   "source": [
    "int_or = utils.swap_genes_if_needed(int_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9651e4-dd93-4886-b0a5-038c8924df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (int_or[['gene_id1', 'gene_id2']].apply(utils.create_pairs, axis = 1)[1] == False).all() #check if swapping works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3476d97-a892-4a1d-a233-174ad88b7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_or = utils.create_features(int_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc34529-ce86-4295-8a60-e28ecf50fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert int_or.groupby('gene_id1').std(numeric_only = True).protein_coding_1.max() == 0\n",
    "assert int_or.groupby('gene_id2').std(numeric_only = True).protein_coding_2.max() == 0\n",
    "\n",
    "assert int_or.groupby('gene_id1').std(numeric_only = True).length_1.max() == 0\n",
    "assert int_or.groupby('gene_id2').std(numeric_only = True).length_2.max() == 0\n",
    "\n",
    "idx = np.random.randint(int_or.shape[0])\n",
    "assert int_or.loc[idx].length_1 == len(int_or.loc[idx].cdna_1)\n",
    "assert int_or.loc[idx].length_2 == len(int_or.loc[idx].cdna_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6106d43-9af8-4b5c-aab5-14dfba61d979",
   "metadata": {},
   "source": [
    "### Gene info df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a1a9a5-9872-4354-aaab-8e13a0d0d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_info1 = int_or[['gene_id1', 'length_1', 'cdna_1', 'protein_coding_1']]\n",
    "gene_info1.columns = ['gene_id', 'length', 'cdna', 'protein_coding']\n",
    "gene_info2 = int_or[['gene_id2', 'length_2', 'cdna_2', 'protein_coding_2']]\n",
    "gene_info2.columns = ['gene_id', 'length', 'cdna', 'protein_coding']\n",
    "gene_info = pd.concat([gene_info1, gene_info2], axis = 0, ignore_index = True).drop_duplicates()\n",
    "#assert set(gene_info.gene_id) == set(df_genes.gene_id)\n",
    "df_genes = df_genes.merge(gene_info)\n",
    "\n",
    "df_genes.UTR5 = df_genes.UTR5.apply(lambda x: int(x) if x!= '/' else np.nan)\n",
    "df_genes.UTR3 = df_genes.UTR3.apply(lambda x: int(x) if x!= '/' else np.nan)\n",
    "df_genes.CDS = df_genes.CDS.apply(lambda x: int(x) if x!= '/' else np.nan)\n",
    "\n",
    "df_genes.to_csv(os.path.join(processed_files_dir, 'df_genes.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2334d7ea-f6a9-4a1e-b6c1-c3076d8ff961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean int_or\n",
    "int_or = int_or.drop(['cdna_1', 'cdna_2'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1efbb-8073-4979-9f94-c1524997142e",
   "metadata": {},
   "source": [
    "### Clean bounding boxes of df interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b11f6f-e14c-48a3-ad5a-4792a75fee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boxes = int_or.filter(['start_map1', 'end_map1', 'start_map2', 'end_map2','area_of_the_interaction'], axis = 1).apply(utils.create_boxes_xywh, axis = 1).rename({0: 'x1', 1: 'y1', 2:'w', 3:'h'}, axis = 1)\n",
    "int_or = pd.concat([int_or, df_boxes], axis = 1).drop(['start_map1', 'end_map1', 'start_map2', 'end_map2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "219a9bab-c76d-4d9a-9837-2c715c05499a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49f892afffd487189d4b92eaf68d659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#approx 11 min\n",
    "diz_int = {}\n",
    "idx = 0\n",
    "for couple in tqdm(int_or.couples.unique()):\n",
    "    subset = int_or[int_or.couples == couple]\n",
    "    list_of_boxes = subset.filter(['x1', 'y1', 'w', 'h']).values.tolist()\n",
    "    new_list_of_boxes = utils.clean_bounding_boxes(list_of_boxes)\n",
    "    row = int_or[int_or.couples == couple].iloc[0]\n",
    "    for box in new_list_of_boxes:\n",
    "        d = dict(row)\n",
    "        d['x1'] = box[0]\n",
    "        d['y1'] = box[1] \n",
    "        d['w'] = box[2]\n",
    "        d['h'] = box[3]\n",
    "        diz_int[idx] = d\n",
    "        idx+=1\n",
    "df_int = pd.DataFrame.from_dict(diz_int, 'index').rename({'gene_id1':'gene1', 'gene_id2':'gene2'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b525d4-4782-4f0e-8744-566718890c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(int_or.couples.unique()) == len(df_int.couples.unique())\n",
    "print(f'#interazioni prima {int_or.shape[0]}, #interazioni dopo: {df_int.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a16cbd7-b99d-4a07-91af-9092738fbfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int.to_csv(os.path.join(processed_files_dir, 'full_paris_info_interactions.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73ae1fab-dbea-413a-b550-cccefb1b89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int = df_int[['couples', 'gene1', 'gene2', \n",
    "                 'interacting', 'length_1', 'length_2',\n",
    "                 'protein_coding_1', 'protein_coding_2',\n",
    "                 'x1', 'y1', 'w', 'h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a2c82b2-db68-468d-9be7-9357490114e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg['interacting'] = False\n",
    "df_neg = df_neg.merge(df_genes[['gene_id', 'length', 'protein_coding']], left_on = 'gene1', right_on = 'gene_id').drop('gene_id', axis = 1).rename({'length': 'length_1','protein_coding':'protein_coding_1'} , axis = 1)\n",
    "df_neg = df_neg.merge(df_genes[['gene_id', 'length', 'protein_coding']], left_on = 'gene2', right_on = 'gene_id').drop('gene_id', axis = 1).rename({'length': 'length_2','protein_coding':'protein_coding_2'} , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45cd86c3-12c6-416b-a57a-33d1d254fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(df_pairs_full.negative) - set(df_neg.couples) == {np.nan} # I have some NaN in the df_pairs_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb684b87-ab9f-4eb4-92e3-d46a15a6cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int1 = df_int[['gene1', 'x1', 'w']].rename({'gene1':'gene', 'x1':'c1',  'w': 'l'}, axis = 1)\n",
    "df_int2 = df_int[['gene2', 'y1', 'h']].rename({'gene2':'gene', 'y1':'c1',  'h': 'l'}, axis = 1)\n",
    "df_coord = pd.concat([df_int1, df_int2], ignore_index = True)#.drop_duplicates().reset_index(drop = True)\n",
    "#df_coord may have duplicates. but this is something I want. If a gene appears more than once, I want it to be sampled according to its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f905d068-a9f7-4b90-be97-20f5261ce4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(df_neg.gene1).union(set(df_neg.gene2)) - set(df_coord.gene) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c996562-83ab-41f2-a9de-9a9aacfe6b1c",
   "metadata": {},
   "source": [
    "### Create fake negative interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42ca2e75-3f07-4b19-9608-adb0e60eab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coord = df_coord.merge(\n",
    "    df_genes.filter(['gene_id', 'UTR5', 'CDS', 'UTR3', 'protein_coding'], axis = 1).rename({'gene_id':'gene'}, axis = 1)\n",
    ")\n",
    "df_coord['where_c1'] = df_coord.apply(utils.where_interacts, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf72c1c-4bf5-4fec-b13b-c68fe8432729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#65 min\n",
    "start_time = time.time()\n",
    "new_cols = df_neg[['couples', 'gene1', 'gene2']].apply(utils.create_fake_coord_neg, axis = 1, args = (df_coord,df_pairs_full,df_int,))\n",
    "print(f\"Total time: {(time.time()-start_time)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046f49e-de25-489b-876b-8964d336efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = new_cols.apply(pd.Series).rename({0:'x1', 1:'y1', 2:'w', 3:'h'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba239a2-1ec9-4400-900a-6e5151cbe8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = pd.concat([df_neg, new_cols], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1de31-9c99-4f76-8c4f-36c2f90fceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_int, df_neg], ignore_index = True, axis = 0)\n",
    "df.to_csv(os.path.join(processed_files_dir, 'final_df.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc574e-a3dd-4a63-b048-7bf108b9a9d0",
   "metadata": {},
   "source": [
    "Now I do checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e7a7b-4096-4669-ac97-195b8e06b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it worked\n",
    "assert (df_neg.x1 <= df_neg.length_1).all()\n",
    "assert ((df_neg.x1 + df_neg.w) <= df_neg.length_1).all()\n",
    "assert (df_neg.y1 <= df_neg.length_2).all()\n",
    "assert ((df_neg.y1 + df_neg.h) <= df_neg.length_2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6b0e3-0d8c-49f8-9fc6-4581e78bccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37 min\n",
    "#check if it worked\n",
    "start_time = time.time()\n",
    "for _, row in df_neg.iterrows():\n",
    "    g1 = row.gene1\n",
    "    g2 = row.gene2\n",
    "    assert [row.x1, row.w] in df_coord[df_coord.gene == g1][['c1', 'l']].values\n",
    "    assert [row.y1, row.h] in df_coord[df_coord.gene == g2][['c1', 'l']].values\n",
    "    if np.random.rand() < 0.0003: #progress\n",
    "        print(f\"{np.round(_/df_neg.shape[0] * 100, 2)}% in {(time.time()-start_time)/60} minutes\")\n",
    "print(f\"Total time: {(time.time()-start_time)/60} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
