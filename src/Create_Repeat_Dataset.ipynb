{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ebb322",
   "metadata": {},
   "outputs": [],
   "source": [
    "its_jupyter_notebook = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8ae948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import dataset.preprocessing as utils\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f4aebf-4c4c-461b-80e2-7d5d88bac9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/giorgio/ENTER/envs/dnabert/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (1,2,16,17,18,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['gene1', 'gene2', 'x1', 'y1', 'w', 'h']\n",
    "df_paris = pd.read_csv(os.path.join(processed_files_dir, 'paris.csv')).filter(columns_to_keep, axis = 1)\n",
    "df_paris['dataset'] = 'paris'\n",
    "df_ricseq = pd.read_csv(os.path.join(processed_files_dir, 'ricseq.csv')).filter(columns_to_keep, axis = 1)\n",
    "df_ricseq['dataset'] = 'ricseq'\n",
    "df_mario = pd.read_csv(os.path.join(processed_files_dir, 'mario.csv')).filter(columns_to_keep, axis = 1)\n",
    "df_mario['dataset'] = 'mario'\n",
    "\n",
    "df_genes_paris_ricseq=pd.read_csv(os.path.join(processed_files_dir, 'df_genes.csv'))[['gene_id', 'cdna', 'length', 'UTR5', 'CDS', 'UTR3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c579d4-2039-4042-b61e-695026b271c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_coord(df_coord, drop_duplicates = True):\n",
    "    #dataset with all the interactinons of the datasets\n",
    "    df_coord['x2'] = df_coord['x1'] + df_coord['w'] \n",
    "    df_coord['y2'] = df_coord['y1'] + df_coord['h'] \n",
    "\n",
    "    df_coord1 = df_coord[['gene1', 'x1', 'x2', 'dataset']].rename({'gene1':'gene_id', 'x1':'start', 'x2':'end'}, axis=1)\n",
    "    df_coord2 = df_coord[['gene2', 'y1', 'y2', 'dataset']].rename({'gene2':'gene_id', 'y1':'start', 'y2':'end'}, axis=1)\n",
    "    if drop_duplicates:\n",
    "        df_coord = pd.concat([df_coord1, df_coord2], axis = 0).drop_duplicates().reset_index(drop = True)\n",
    "    else:\n",
    "        df_coord = pd.concat([df_coord1, df_coord2], axis = 0).reset_index(drop = True)\n",
    "    return df_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2f562f-01b7-45e9-9b36-1036f3a34c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coord = create_df_coord(\n",
    "    pd.concat([df_paris, df_ricseq, df_mario], axis = 0).reset_index(drop = True)\n",
    ").merge(df_genes_paris_ricseq[['gene_id', 'length', 'UTR5', 'CDS', 'UTR3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cb773-9285-4088-abfc-3598b384251f",
   "metadata": {},
   "source": [
    "Splash Ã¨ un discorso a parte perche ha altre annotazioni dei geni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d74334-f04c-424c-b2b8-b386fed3ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splash = pd.read_csv(os.path.join(processed_files_dir, 'splash.csv')).filter(columns_to_keep, axis = 1)\n",
    "df_splash['dataset'] = 'splash'\n",
    "df_genes_splash=pd.read_csv(os.path.join(processed_files_dir, 'df_genes_splash.csv'))[['gene_id', 'cdna', 'length', 'UTR5', 'CDS', 'UTR3']]\n",
    "\n",
    "df_coord_splash = create_df_coord(\n",
    "    df_splash\n",
    ").merge(df_genes_splash[['gene_id', 'length', 'UTR5', 'CDS', 'UTR3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf48e80-10e9-4282-8f70-0bb42c4125ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (df_coord['end'] <= df_coord['length']).all()\n",
    "assert (df_coord_splash['end'] <= df_coord_splash['length']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8da86079-f198-4586-973e-8d4dce9d4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative_sample(len_fake_neg_region, range_to_search_negative, df_coord, num_tries = 100):\n",
    "    s, e = range_to_search_negative\n",
    "    for i in range(num_tries):\n",
    "        try:\n",
    "            start_coord = np.random.randint(s, (e - len_fake_neg_region))\n",
    "            end_coord = start_coord + len_fake_neg_region\n",
    "            for _, row_coord in df_coord.iterrows():\n",
    "                #print( set(range(start_coord,end_coord)) )\n",
    "                assert set(range(start_coord,end_coord)).intersection(set(range(int(row_coord.start),int(row_coord.end)))) == set()\n",
    "            return start_coord, end_coord\n",
    "        except:\n",
    "            if num_tries%10 == 0 :\n",
    "                len_fake_neg_region = len_fake_neg_region//2\n",
    "            continue\n",
    "    else:\n",
    "        return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc229c49-a834-41f7-86fd-4d1a09241410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_fake_neg_region = int(np.round((df_coord.end - df_coord.start).mean(), 0))\n",
    "# print('length of fake negative region =', len_fake_neg_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8454d70-3f77-4eff-a031-8f97779a0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_cdna_slice(x):\n",
    "    return x['cdna'][x.start:x.end]\n",
    "\n",
    "def check_intersection(a, b, c, d):\n",
    "    a = int(a)\n",
    "    b = int(b)\n",
    "    c = int(c)\n",
    "    d = int(d)\n",
    "    if (len(set(range(a, b)).intersection(set(range(c, d)))) > 0 ):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def create_posneg(df_coord, df_genes, fixed_neg_region = 0):\n",
    "    diz = {}\n",
    "    gene_list = list(set(df_coord.gene_id))\n",
    "    index = 0\n",
    "    to_drop = 0\n",
    "    \n",
    "    #per ogni gene campiono 1 positivo e 1 negativo\n",
    "    for gene in tqdm(gene_list):\n",
    "        df_coord_gene = df_coord[df_coord['gene_id'] == gene]\n",
    "        positive_sampled = df_coord_gene.sample(1).iloc[0]\n",
    "        length = positive_sampled.length\n",
    "        gene_id = positive_sampled.gene_id\n",
    "        dataset = positive_sampled.dataset\n",
    "        positive_start = int(positive_sampled.start)\n",
    "        positive_end = int(positive_sampled.end)\n",
    "        \n",
    "        pc = not np.isnan(positive_sampled.CDS)\n",
    "        if pc == False:\n",
    "            range_to_search_negative = (0, length)\n",
    "            where = 'none'\n",
    "        else:\n",
    "            if check_intersection(positive_start, positive_end, 0, positive_sampled.UTR5):\n",
    "                range_to_search_negative = (0, positive_sampled.UTR5)\n",
    "                where = 'utr5'\n",
    "            elif check_intersection(positive_start, positive_end, positive_sampled.UTR5, positive_sampled.CDS):\n",
    "                range_to_search_negative = (positive_sampled.UTR5, positive_sampled.CDS)\n",
    "                where = 'cds'\n",
    "            elif check_intersection(positive_start, positive_end, positive_sampled.CDS, positive_sampled.UTR3):\n",
    "                range_to_search_negative = (positive_sampled.CDS, positive_sampled.UTR3)\n",
    "                where = 'utr3'\n",
    "            \n",
    "        if fixed_neg_region == 0:\n",
    "            len_neg = (positive_end-positive_start)\n",
    "        else:\n",
    "            len_neg = fixed_neg_region\n",
    "        \n",
    "        negative_start, negative_end = create_negative_sample(len_neg, range_to_search_negative, df_coord_gene)\n",
    "        if np.isnan(negative_start):\n",
    "            positive_start, positive_end = np.nan, np.nan #I will drop this positive\n",
    "            to_drop += 1\n",
    "        \n",
    "        actual_neg_len = (negative_end - negative_start)\n",
    "        distance = len_neg-actual_neg_len\n",
    "        \n",
    "        if actual_neg_len < len_neg:\n",
    "            neg_window_is_reduced = True\n",
    "        else:\n",
    "            neg_window_is_reduced = False\n",
    "            \n",
    "        diz[index] = {'gene_id':gene_id, 'start':positive_start, 'end':positive_end, 'length':length, 'dataset':dataset, 'how': 'positive', 'where':where, 'neg_window_is_reduced':neg_window_is_reduced, 'distance':distance}\n",
    "        index += 1\n",
    "        diz[index] = {'gene_id':gene_id, 'start':negative_start, 'end':negative_end, 'length':length, 'dataset':dataset, 'how': 'negative', 'where':where, 'neg_window_is_reduced':neg_window_is_reduced, 'distance':distance}\n",
    "        index += 1\n",
    "        \n",
    "    df_posneg = pd.DataFrame.from_dict(diz, 'index')\n",
    "    df_posneg = df_posneg.merge(df_genes[['gene_id', 'cdna']])\n",
    "    df_posneg = df_posneg.dropna().reset_index(drop = True)\n",
    "    df_posneg['start'] = df_posneg.start.astype(int)\n",
    "    df_posneg['end'] = df_posneg.end.astype(int)\n",
    "    print('# dropped', to_drop)\n",
    "    df_posneg['cdna_slice'] = df_posneg.apply(obtain_cdna_slice, axis = 1)\n",
    "    df_posneg = df_posneg.drop('cdna', axis = 1)\n",
    "    df_posneg = df_posneg.rename({'cdna_slice':'cdna'}, axis = 1)\n",
    "    df_posneg['id_query'] = df_posneg['gene_id'] + '_' + df_posneg['start'].astype(str) + '_' + df_posneg['end'].astype(str)\n",
    "    return df_posneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "833922ed-b932-4f44-bab0-186f5220015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260b5ba16313476087d08cc100e5d5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# dropped 0\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg_splash.csv')\n",
    "if os.path.isfile(filepath):\n",
    "    df_posneg_splash = pd.read_csv(filepath)\n",
    "else:\n",
    "    df_posneg_splash = create_posneg(df_coord_splash, df_genes_splash, fixed_neg_region = 0)\n",
    "    df_posneg_splash.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d917f57-501e-4cce-9bc0-409a31ba9720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7ee9eac1d24285891ed6e3b5046fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44419 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# dropped 0\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg_paris_ricseq.csv')\n",
    "if os.path.isfile(filepath):\n",
    "    df_posneg_paris_ricseq = pd.read_csv(filepath)\n",
    "else:\n",
    "    df_posneg_paris_ricseq = create_posneg(df_coord, df_genes_paris_ricseq)\n",
    "    df_posneg_paris_ricseq.to_csv(os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg_paris_ricseq.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef2290dc-d333-4ea1-bf24-b32e23dd8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg.csv')\n",
    "if os.path.isfile(filepath):\n",
    "    df_posneg = pd.read_csv(filepath)\n",
    "else:\n",
    "    df_posneg = pd.concat([df_posneg_paris_ricseq, df_posneg_splash], axis = 0).reset_index(drop = True)\n",
    "    df_posneg.to_csv(os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_posneg.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbdad0-0870-49cb-944e-e8ba740e87f5",
   "metadata": {},
   "source": [
    "### Now the repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffbee6c1-0b56-4e26-9366-ba5f74e624cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings', 'df_repeats.csv')\n",
    "if os.path.isfile(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "else:\n",
    "    mm = pd.read_csv(os.path.join(original_files_dir, 'repeats.mm.bed'), sep = '\\t', header = None)\n",
    "    hs = pd.read_csv(os.path.join(original_files_dir, 'repeats.hs.bed'), sep = '\\t', header = None)\n",
    "\n",
    "    df = pd.concat([mm, hs], axis = 0).reset_index(drop = True)\n",
    "\n",
    "    df = df.rename({0:'chrom', 1:'start', 2:'end', 6:'feature'}, axis = 1)\n",
    "\n",
    "    df = df[['chrom', 'start', 'end', 'feature']]\n",
    "    \n",
    "    info = utils.read_dataframe(os.path.join(original_files_dir, 'index_bio_regions.Tx.RI_ALL.txt'), columns_to_drop = ['Unnamed: 0'])\n",
    "    info1 = info[['chrom_1', 'ensembl_gene_id_1']].rename({'chrom_1':'chrom', 'ensembl_gene_id_1':'gene_id'}, axis = 1)\n",
    "    info2 = info[['chrom_2', 'ensembl_gene_id_2']].rename({'chrom_2':'chrom', 'ensembl_gene_id_2':'gene_id'}, axis = 1)\n",
    "    info = pd.concat([info1, info2], axis = 0).drop_duplicates().reset_index(drop = True)\n",
    "    \n",
    "    # remove the genes not in our datasets\n",
    "    genes_to_remove = set(df.chrom) - set(info.chrom)\n",
    "\n",
    "    df = df[~df.chrom.isin(genes_to_remove)].reset_index(drop = True)\n",
    "\n",
    "    df = df.merge(info)\n",
    "\n",
    "    df = df.merge(df_genes_paris_ricseq).reset_index(drop = True)\n",
    "\n",
    "    assert (df.length >= df.end).all()\n",
    "\n",
    "    df['start'] = df.start.astype(int)\n",
    "    df['end'] = df.end.astype(int)\n",
    "    df['cdna_slice'] = df.apply(obtain_cdna_slice, axis = 1)\n",
    "    df = df.drop('cdna', axis = 1)\n",
    "    df = df.rename({'cdna_slice':'cdna'}, axis = 1)\n",
    "    df['id_query'] = df['gene_id'] + '_' + df['start'].astype(str) + '_' + df['end'].astype(str)\n",
    "    \n",
    "    \n",
    "    interacting_list = []\n",
    "    for _, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        interacting = False\n",
    "        gene = row.gene_id\n",
    "        region = set(range(int(row.start), int(row.end)))\n",
    "        int_subset = df_coord[df_coord.gene_id == gene]\n",
    "        for _, row_int in int_subset.iterrows():\n",
    "            region_int = set(range(int(row_int.start), int(row_int.end)))\n",
    "            if len(region.intersection(region_int)) > 0:\n",
    "                interacting = True\n",
    "        interacting_list.append(interacting)\n",
    "    df['len_feature'] = df['end']-df['start']\n",
    "    df.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a6cff-b047-4546-b59c-bc160cedd004",
   "metadata": {},
   "source": [
    "# Create df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95accfbc-a5bb-4805-9b41-e5f603c78f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = os.path.join(processed_files_dir, 'nt_data', 'mean_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00febc64-1c66-4c2f-9fbd-30cb2dbb0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query = pd.concat([df[['id_query', 'cdna']], df_posneg[['id_query', 'cdna']]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f08f342-651e-4d25-8868-c5f4fd1c1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(os.path.join(emb_dir, '32'))\n",
    "all_files = list(pd.Series(all_files).str.extractall('(.*)\\.npy').reset_index()[0])\n",
    "df_query = df_query[~df_query.id_query.isin(all_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "579f8ee2-1a0e-495f-8bfe-dd8231e29084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query.to_csv(os.path.join(emb_dir, 'embedding_query.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3e6d9c5-e80d-4d09-b317-19da4ecbf7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated # hours: 14.51\n",
      "estimated # days: 0.6\n",
      "estimated terabytes (pessimistic): 0.63\n",
      "estimated terabytes (realistic): 0.41\n"
     ]
    }
   ],
   "source": [
    "def estimate_time_and_space(n_samples):\n",
    "    #TIME\n",
    "    minutes = 3219*n_samples/(228278)\n",
    "    hours = minutes/60\n",
    "    days = hours/24\n",
    "    print('estimated # hours:', np.round(hours, 2))\n",
    "    print('estimated # days:', np.round(days, 2))\n",
    "\n",
    "    mb = 10.2*n_samples\n",
    "    gb = mb/1000\n",
    "    tb = gb/1000\n",
    "    print('estimated terabytes (pessimistic):', np.round(tb, 2))\n",
    "    mb = 1995*n_samples/(300)\n",
    "    gb = mb/1000\n",
    "    tb = gb/1000\n",
    "    print('estimated terabytes (realistic):', np.round(tb, 2))\n",
    "estimate_time_and_space(df_query.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
