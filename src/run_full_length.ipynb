{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with real ground truth - Pulldown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "<class 'transformers.tokenization_dna.DNATokenizer'>\n"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, Subset, DataLoader, DistributedSampler\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from dataset.data import (\n",
    "    RNADatasetInference,\n",
    "    seed_everything,\n",
    ")\n",
    "import util.misc as utils\n",
    "from models.binary_classifier import build as build_model\n",
    "from train_binary_cl import (\n",
    "    get_args_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.abspath('.'))\n",
    "original_files_dir = os.path.join(ROOT_DIR, \"dataset\", \"original_files\")\n",
    "processed_files_dir = os.path.join(ROOT_DIR, \"dataset\", \"processed_files\")\n",
    "external_dataset_files_dir = os.path.join(ROOT_DIR, \"dataset\", \"external_dataset\", \"pulldown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['']\n",
    "parser = argparse.ArgumentParser('Training', parents=[get_args_parser()])\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_size = 350\n",
    "device = 'cuda:0'\n",
    "num_workers = 10\n",
    "batch_size = 32\n",
    "args.output_dir = os.path.join(ROOT_DIR, 'checkpoints', 'binary_cl')\n",
    "args.dataset_path = os.path.join(ROOT_DIR, 'dataset')\n",
    "args.resume = os.path.join(args.output_dir, 'checkpoint.pth')\n",
    "args.resume = args.resume.replace('checkpoint.pth', 'best_model.pth')\n",
    "bert_pretrained_dir = os.path.join(ROOT_DIR, 'dataset', 'pre_trained_DNABERT', '6-new-12w-0')\n",
    "ufold_dir = os.path.join(ROOT_DIR, 'UFold_dependencies')\n",
    "ufold_path= os.path.join(ufold_dir, 'models', 'ufold_train_alldata.pt')\n",
    "assert os.path.isfile(args.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed)\n",
    "dataset = RNADatasetInference(\n",
    "    gene_info_path = os.path.join(external_dataset_files_dir, \"genes.fa\"),\n",
    "    interactions_path = os.path.join(external_dataset_files_dir, \"pairs.txt\"),\n",
    "    dot_bracket_path = os.path.join(external_dataset_files_dir, \"dot_bracket.txt\"),\n",
    "    step_size=step_size\n",
    ")\n",
    "\n",
    "sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size = args.batch_size, sampler=sampler,\n",
    "                             drop_last=False, collate_fn=utils.collate_fn, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, criterion, postprocessors = build_model(args, bert_pretrained_dir, ufold_path)\n",
    "model.to(device)\n",
    "model_without_ddp = model\n",
    "\n",
    "checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "model_without_ddp.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dc885d57e64971b34a3cd6d70cad16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probability = []\n",
    "g1 = []\n",
    "g2 = []\n",
    "len_g1 = []\n",
    "len_g2 = []\n",
    "x1 = []\n",
    "x2 = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for samples, targets in tqdm(data_loader):\n",
    "        rna1, rna2 = samples\n",
    "        rna1[0] = rna1[0].to(device)\n",
    "        rna2[0] = rna2[0].to(device)\n",
    "        rna1[1].tensors = rna1[1].tensors.to(device)\n",
    "        rna2[1].tensors = rna2[1].tensors.to(device)\n",
    "        rna1[1].mask = rna1[1].mask.to(device)\n",
    "        rna2[1].mask = rna2[1].mask.to(device)\n",
    "        \n",
    "        outputs = model(rna1, rna2)\n",
    "        probability += outputs['cnn_output'].softmax(-1)[:, 1].tolist()\n",
    "        g1 += [t['gene1'] for t in targets]\n",
    "        g2 += [t['gene2'] for t in targets]\n",
    "        len_1 = np.array([(t['bbox'].x2 - t['bbox'].x1) for t in targets])\n",
    "        len_2 = np.array([(t['bbox'].y2 - t['bbox'].y1) for t in targets])\n",
    "        len_g1 += list(len_1)\n",
    "        len_g2 += list(len_2)\n",
    "        x1 +=[t['bbox'].x1 for t in targets]\n",
    "        x2 +=[t['bbox'].x2 for t in targets]\n",
    "        y1 +=[t['bbox'].y1 for t in targets]\n",
    "        y2 +=[t['bbox'].y2 for t in targets]\n",
    "\n",
    "res = pd.DataFrame({\n",
    "    'probability':probability,\n",
    "    'g1':g1,\n",
    "    'g2':g2,\n",
    "    'x1':x1,\n",
    "    'x2':x2,\n",
    "    'y1':y1,\n",
    "    'y2':y2,\n",
    "    'len_g1': len_g1,\n",
    "    'len_g2': len_g2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulldown_dir = os.path.join(ROOT_DIR, 'dataset', 'external_dataset', 'pulldown')\n",
    "pos = os.path.join(pulldown_dir, 'cand_99.ids.fa')\n",
    "neg = os.path.join(pulldown_dir, 'ctrl_99.ids.fa')\n",
    "\n",
    "fasta_sequences = [SeqIO.parse(open(pos),'fasta'), \n",
    "                   SeqIO.parse(open(neg), 'fasta'),\n",
    "                  ]\n",
    "\n",
    "pos_samples = []\n",
    "neg_samples = []\n",
    "for k in range(len(fasta_sequences)):\n",
    "    for _, fasta in enumerate(fasta_sequences[k]):\n",
    "        name = str(fasta.description)\n",
    "        if k == 0:\n",
    "            pos_samples.append(name)\n",
    "        elif k == 1:\n",
    "            neg_samples.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140\n"
     ]
    }
   ],
   "source": [
    "neg = res[res.g2.isin(neg_samples)]\n",
    "print(neg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5219806763285024\n",
      "0.4587731621181221\n"
     ]
    }
   ],
   "source": [
    "print(neg[neg.probability < 0.5].shape[0]/neg.shape[0])\n",
    "print(neg.probability.mean())\n",
    "\n",
    "d = {}\n",
    "for g2 in neg.g2.unique():\n",
    "    subset = neg[neg.g2 == g2]\n",
    "    d[g2] = {'n_tot':subset.shape[0],\n",
    "            'predicted_pos':subset[subset.probability>0.5].shape[0]}\n",
    "df_neg = pd.DataFrame.from_dict(d, orient = 'index').reset_index().rename({'index':'gene'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\n"
     ]
    }
   ],
   "source": [
    "pos = res[res.g2.isin(pos_samples)]\n",
    "print(pos.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47578692493946734\n",
      "0.45637122840173205\n"
     ]
    }
   ],
   "source": [
    "print(pos[pos.probability > 0.5].shape[0]/pos.shape[0])\n",
    "print(pos.probability.mean())\n",
    "d = {}\n",
    "for g2 in pos.g2.unique():\n",
    "    subset = pos[pos.g2 == g2]\n",
    "    d[g2] = {'n_tot':subset.shape[0],\n",
    "            'predicted_pos':subset[subset.probability>0.5].shape[0]}\n",
    "df_pos = pd.DataFrame.from_dict(d, orient = 'index').reset_index().rename({'index':'gene'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.067857142857143"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg.predicted_pos.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg[df_neg['predicted_pos']>0].shape[0]/df_neg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1454545454545455"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos.predicted_pos.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272727272727272"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos[df_pos['predicted_pos']>0].shape[0]/df_pos.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "28f202d77f1a85c5cab767fd2089c1bba19c245ba743de17ef12d30078485197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
